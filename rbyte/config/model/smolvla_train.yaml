config_path: ???
resume: false
# Policy params
load_vlm_weights: True
prefix_length: 0
pad_language_to: "max_length"
num_vlm_layers: 16
# Training params
optimizer_lr: 2.5e-05
optimizer_betas: 
  - 0.9
  - 0.95
optimizer_weight_decay: 1e-10
optimizer_grad_clip_norm: 10.0
scheduler_decay_lr: 6.25e-07
scheduler_warmup_steps: 66800
scheduler_decay_steps: 2004000
steps: 1336000
batch_size: 32
# Architecture params
## Architecture suffix params: horizon
chunk_size: 50
n_action_steps: 50
## Architecture prefix params: clip
use_separate_intent: False
max_action_dim: 32
max_state_dim: 32
max_intent_dim: 32
use_image_norm: 1
use_context: True
freeze_vision_encoder: True
# Loss params
use_masked_loss: False
use_acc_loss: False
# Logging params
log_freq: 50
eval_freq: 10000
train_run: train_smolvla_rmind_waypoints_chunk_6_hp

