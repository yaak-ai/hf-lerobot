config_path: ???
resume: false
# Policy params
load_vlm_weights: True
prefix_length: 0
pad_language_to: "max_length"
num_vlm_layers: 16
# Training params
optimizer_lr: 5e-5
optimizer_betas: 
  - 0.9
  - 0.95
optimizer_weight_decay: 1e-10
optimizer_grad_clip_norm: 10.0
scheduler_decay_lr: 1.25E-6
scheduler_warmup_steps: 33400
scheduler_decay_steps: 1002000
steps: 668000
batch_size: 32
# Architecture params
## Architecture suffix params: horizon
chunk_size: 50
n_action_steps: 50
## Architecture prefix params: clip
use_separate_intent: True
max_action_dim: 32
max_state_dim: 32
max_intent_dim: 32
use_image_norm: 1
use_context: True
freeze_vision_encoder: True
## Architecture masking params
use_state_masking: True
state_masking_probability: 0.25
# Loss params
use_masked_loss: False
use_acc_loss: False
# Logging params
log_freq: 50
eval_freq: 10000
train_run: train_smolvla_rmind_waypoints_rotated_mask_speed_chunk_6_separate
